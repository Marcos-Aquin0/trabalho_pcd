{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# K-means 1D - Etapa 1: Paralelização com OpenMP\n",
        "\n",
        "Este notebook implementa a **Etapa 1** do projeto, focada na paralelização do K-means 1D usando OpenMP para CPUs de memória compartilhada.\n",
        "\n",
        "O fluxo de trabalho é o seguinte:\n",
        "1.  **Configuração:** Preparar os dados de entrada (`dados.csv`) e os centróides iniciais (`centroides_iniciais.csv`).\n",
        "2.  **Implementação (Opção A: Reduction):** Criar a primeira versão paralela (`kmeans_1d_naive_parallel.c`) usando a cláusula `reduction` para paralelizar os laços `assignment_step` e `update_step`.\n",
        "3.  **Benchmark (Opção A):** Executar um script de shell para testar a implementação A com diferentes números de threads (2, 4, 8, 16) e políticas de `schedule` (`static`, `dynamic` com vários *chunks*). O script calcula automaticamente o *Speedup* e a *Eficiência* em relação à execução com 1 thread.\n",
        "4.  **Implementação (Opção B: Critical):** Criar uma segunda versão (`kmeans_1d_naive_parallel_critical.c`) que usa `#pragma omp critical` no `update_step`, como alternativa ao `reduction`.\n",
        "5.  **Benchmark (Opção B):** Executar um script de benchmark similar para a implementação B, permitindo uma análise comparativa do impacto da seção crítica no desempenho.\n",
        "6.  **Análise de Convergência:** Plotar os gráficos de SSE por iteração de todas as execuções para validar a corretude (garantir que todos os resultados são idênticos)."
      ],
      "metadata": {
        "id": "intro_header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A: Configuração dos Dados e Centróides\n",
        "\n",
        "Esta seção prepara os arquivos de entrada necessários para todas as execuções.\n",
        "\n",
        "1.  `dados.csv`: Gerado a partir do `city_temperature.csv`, contém ~2 milhões de registros de temperatura limpos.\n",
        "2.  `centroides_iniciais.csv`: Contém 16 centróides iniciais fixos para garantir a reprodutibilidade dos testes."
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRAWEdjEuETi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carrega o CSV, limpa os dados (-99) e salva os dados 1D (AvgTemperature)\n",
        "df = pd.read_csv('/content/city_temperature.csv', dtype={'State': 'str', 'AvgTemperature': 'float'})\n",
        "df = df['AvgTemperature'].replace(-99, pd.NA).dropna()\n",
        "df.to_csv('dados.csv', index=False, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile centroides_iniciais.csv\n",
        "50.500000\n",
        "88.300000\n",
        "41.500000\n",
        "36.400000\n",
        "15.800000\n",
        "79.200000\n",
        "86.100000\n",
        "77.200000\n",
        "85.200000\n",
        "84.200000\n",
        "71.200000\n",
        "77.300000\n",
        "83.300000\n",
        "61.100000\n",
        "53.200000\n",
        "36.600000"
      ],
      "metadata": {
        "id": "7stn9L6cvy4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# B: Implementação Paralela (Opção A: Reduction)\n",
        "\n",
        "Esta é a implementação paralela principal (`kmeans_1d_naive_parallel.c`).\n",
        "\n",
        "- **`assignment_step_1d`**: O laço `for` principal (sobre N) é paralelizado com `#pragma omp parallel for` e usa `reduction(+:sse)` para acumular o SSE de forma segura.\n",
        "- **`update_step_1d`**: O laço de acumulação (sobre N) é paralelizado usando `reduction(+:sum[:K], cnt[:K])` para acumular as somas e contagens de cada cluster de forma eficiente.\n",
        "- **Medição de Tempo**: O `main` foi modificado para usar `omp_get_wtime()` para uma medição precisa do *wall-clock time*.\n",
        "- **Agendamento**: `schedule(runtime)` é usado para que a política de agendamento possa ser controlada por variáveis de ambiente (`OMP_SCHEDULE`)."
      ],
      "metadata": {
        "id": "impl_a_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile kmeans_1d_naive_parallel.c\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "#include <omp.h>\n",
        "\n",
        "/* ---------- util CSV 1D: (funções inalteradas) ---------- */\n",
        "static int count_rows(const char *path){\n",
        "    FILE *f = fopen(path, \"r\");\n",
        "    if(!f){ fprintf(stderr,\"Erro ao abrir %s\\n\", path); exit(1); }\n",
        "    int rows=0; char line[8192];\n",
        "    while(fgets(line,sizeof(line),f)){\n",
        "        int only_ws=1;\n",
        "        for(char *p=line; *p; p++){\n",
        "            if(*p!=' ' && *p!='\\t' && *p!='\\n' && *p!='\\r'){ only_ws=0; break; }\n",
        "        }\n",
        "        if(!only_ws) rows++;\n",
        "    }\n",
        "    fclose(f);\n",
        "    return rows;\n",
        "}\n",
        "\n",
        "static double *read_csv_1col(const char *path, int *n_out){\n",
        "    int R = count_rows(path);\n",
        "    if(R<=0){ fprintf(stderr,\"Arquivo vazio: %s\\n\", path); exit(1); }\n",
        "    double *A = (double*)malloc((size_t)R * sizeof(double));\n",
        "    if(!A){ fprintf(stderr,\"Sem memoria para %d linhas\\n\", R); exit(1); }\n",
        "    FILE *f = fopen(path, \"r\");\n",
        "    if(!f){ fprintf(stderr,\"Erro ao abrir %s\\n\", path); free(A); exit(1); }\n",
        "    char line[8192];\n",
        "    int r=0;\n",
        "    while(fgets(line,sizeof(line),f)){\n",
        "        int only_ws=1;\n",
        "        for(char *p=line; *p; p++){\n",
        "            if(*p!=' ' && *p!='\\t' && *p!='\\n' && *p!='\\r'){ only_ws=0; break; }\n",
        "        }\n",
        "        if(only_ws) continue;\n",
        "        const char *delim = \",; \\t\";\n",
        "        char *tok = strtok(line, delim);\n",
        "        if(!tok){ fprintf(stderr,\"Linha %d sem valor em %s\\n\", r+1, path); free(A); fclose(f); exit(1); }\n",
        "        A[r] = atof(tok);\n",
        "        r++;\n",
        "        if(r>R) break;\n",
        "    }\n",
        "    fclose(f);\n",
        "    *n_out = R;\n",
        "    return A;\n",
        "}\n",
        "\n",
        "static void write_assign_csv(const char *path, const int *assign, int N){\n",
        "    // ... (código inalterado)\n",
        "}\n",
        "\n",
        "static void write_centroids_csv(const char *path, const double *C, int K){\n",
        "    // ... (código inalterado)\n",
        "}\n",
        "\n",
        "/* ---------- k-means 1D: Paralelizado com OpenMP ---------- */\n",
        "static double assignment_step_1d(const double *X, const double *C, int *assign, int N, int K){\n",
        "    double sse = 0.0;\n",
        "    #pragma omp parallel for schedule(runtime) reduction(+:sse)\n",
        "    for(int i=0;i<N;i++){\n",
        "        int best = -1;\n",
        "        double bestd = 1e300;\n",
        "        for(int c=0;c<K;c++){\n",
        "            double diff = X[i] - C[c];\n",
        "            double d = diff*diff;\n",
        "            if(d < bestd){ bestd = d; best = c; }\n",
        "        }\n",
        "        assign[i] = best;\n",
        "        sse += bestd;\n",
        "    }\n",
        "    return sse;\n",
        "}\n",
        "\n",
        "static void update_step_1d(const double *X, double *C, const int *assign, int N, int K){\n",
        "    double *sum = (double*)calloc((size_t)K, sizeof(double));\n",
        "    int *cnt = (int*)calloc((size_t)K, sizeof(int));\n",
        "    if(!sum || !cnt){ fprintf(stderr,\"Sem memoria no update\\n\"); exit(1); }\n",
        "\n",
        "    // Paralelizado com reduction para os vetores sum e cnt\n",
        "    #pragma omp parallel for schedule(runtime) reduction(+:sum[0:K]) reduction(+:cnt[0:K])\n",
        "    for(int i = 0; i < N; i++){\n",
        "        int a = assign[i];\n",
        "        sum[a] += X[i];\n",
        "        cnt[a] += 1;\n",
        "    }\n",
        "\n",
        "    // Laço final (rápido) permanece sequencial\n",
        "    for(int c=0;c<K;c++){\n",
        "        if(cnt[c] > 0) C[c] = sum[c] / (double)cnt[c];\n",
        "        else           C[c] = X[0];\n",
        "    }\n",
        "    free(sum); free(cnt);\n",
        "}\n",
        "\n",
        "/* ---------- K-means principal ---------- */\n",
        "static void kmeans_1d(const double *X, double *C, int *assign,\n",
        "                      int N, int K, int max_iter, double eps,\n",
        "                      int *iters_out, double *sse_out, FILE *f_sse)\n",
        "{\n",
        "    double prev_sse = 1e300;\n",
        "    double sse = 0.0;\n",
        "    int it;\n",
        "\n",
        "    for(it=0; it<max_iter; it++){\n",
        "        sse = assignment_step_1d(X, C, assign, N, K);\n",
        "        if(f_sse) fprintf(f_sse, \"%d,%.6f\\n\", it + 1, sse);\n",
        "\n",
        "        double rel = fabs(sse - prev_sse) / (prev_sse > 0.0 ? prev_sse : 1.0);\n",
        "        printf(\"Iteration %d, SSE: %f\\n\", it + 1, sse);\n",
        "        if(rel < eps){ it++; break; }\n",
        "\n",
        "        update_step_1d(X, C, assign, N, K);\n",
        "        prev_sse = sse;\n",
        "    }\n",
        "    *iters_out = it;\n",
        "    *sse_out = sse;\n",
        "}\n",
        "\n",
        "/* ---------- main ---------- */\n",
        "int main(int argc, char **argv){\n",
        "    if(argc < 3){\n",
        "        printf(\"Uso: %s dados.csv centroides_iniciais.csv [max_iter=50] [eps=1e-4] [sse_iter.csv]\\n\", argv[0]);\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    const char *pathX = argv[1];\n",
        "    const char *pathC = argv[2];\n",
        "    int max_iter = (argc>3)? atoi(argv[3]) : 50;\n",
        "    double eps   = (argc>4)? atof(argv[4]) : 1e-4;\n",
        "    const char *sse_file    = (argc>5)? argv[5] : NULL;\n",
        "\n",
        "    FILE *f_sse = NULL;\n",
        "    if(sse_file){\n",
        "        f_sse = fopen(sse_file, \"w\");\n",
        "        if(!f_sse){ fprintf(stderr,\"Erro ao abrir %s para escrita\\n\", sse_file); }\n",
        "        else fprintf(f_sse, \"iteracao,sse\\n\");\n",
        "    }\n",
        "\n",
        "    int N=0, K=0;\n",
        "    double *X = read_csv_1col(pathX, &N);\n",
        "    double *C = read_csv_1col(pathC, &K);\n",
        "    int *assign = (int*)malloc((size_t)N * sizeof(int));\n",
        "    if(!assign){ fprintf(stderr,\"Sem memoria para assign\\n\"); free(X); free(C); return 1; }\n",
        "\n",
        "    // Medição de tempo com omp_get_wtime() para wall-clock time\n",
        "    double t0 = omp_get_wtime();\n",
        "\n",
        "    int iters = 0; double sse = 0.0;\n",
        "    kmeans_1d(X, C, assign, N, K, max_iter, eps, &iters, &sse, f_sse);\n",
        "\n",
        "    double t1 = omp_get_wtime();\n",
        "    double ms = (t1 - t0) * 1000.0;\n",
        "\n",
        "    if(f_sse) fclose(f_sse);\n",
        "\n",
        "    printf(\"K-means 1D (Parallel - Reduction)\\n\");\n",
        "    printf(\"N=%d K=%d max_iter=%d eps=%g\\n\", N, K, max_iter, eps);\n",
        "    printf(\"Threads: %d\\n\", omp_get_max_threads());\n",
        "    printf(\"Iterações: %d | SSE final: %.6f | Tempo: %.1f ms\\n\", iters, sse, ms);\n",
        "\n",
        "    free(assign); free(X); free(C);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "QwYujOTmwVwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  C: Benchmark (Opção A: Reduction)\n",
        "\n",
        "Este script de shell automatiza o benchmark da implementação com `reduction`.\n",
        "\n",
        "1.  Compila o código com a flag `-fopenmp`.\n",
        "2.  Executa uma vez com `OMP_NUM_THREADS=1` para obter o tempo sequencial (`T_seq`) como baseline.\n",
        "3.  Itera sobre o número de threads `T = {2, 4, 8, 16}`.\n",
        "4.  Para cada `T`, testa `schedule(static)`.\n",
        "5.  Para cada `T`, testa `schedule(dynamic)` com `chunk = {1, 10, 100, 1000}`.\n",
        "6.  Calcula `Speedup = T_seq / T_paralelo` e `Eficiência = Speedup / T`.\n",
        "7.  Salva todos os resultados em `resultados.csv`."
      ],
      "metadata": {
        "id": "bench_a_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "echo \"Compilando a versão paralela (Reduction)...\"\n",
        "gcc -O2 -std=c99 -fopenmp kmeans_1d_naive_parallel.c -o kmeans_parallel_reduction -lm\n",
        "\n",
        "# Arquivo de resultados\n",
        "echo \"Num_Threads,Schedule,Chunk,Tempo(ms),SSE_final,Iteracoes,Speedup,Eficiência\" > resultados.csv\n",
        "\n",
        "# Executa versão sequencial (T=1) para referência\n",
        "echo \"Executando o Baseline (Threads=1)...\"\n",
        "export OMP_NUM_THREADS=1\n",
        "export OMP_SCHEDULE=\"static\"\n",
        "T_seq=$(./kmeans_parallel_reduction dados.csv centroides_iniciais.csv 500 0.0001 sse_evolution_seq.csv | grep \"Tempo:\" | tail -n1 | sed -E 's/.*Tempo: ([0-9.]+) ms.*/\\1/')\n",
        "echo \"Tempo sequencial = $T_seq ms\"\n",
        "echo \"1,static,N/A,$T_seq,N/A,N/A,1.0000,1.0000\" >> resultados.csv\n",
        "\n",
        "# Loop pelos schedules e threads\n",
        "for num_t in 2 4 8 16; do\n",
        "  export OMP_NUM_THREADS=$num_t\n",
        "\n",
        "  for sched in static dynamic; do\n",
        "    if [[ \"$sched\" == \"static\" ]]; then\n",
        "      export OMP_SCHEDULE=\"static\"\n",
        "      chunk=\"padrão\"\n",
        "\n",
        "      echo \"==========================================\"\n",
        "      echo \"Executando (Reduction): $sched (chunk=$chunk, threads=$num_t)\"\n",
        "      echo \"==========================================\"\n",
        "\n",
        "      saida=$(./kmeans_parallel_reduction dados.csv centroides_iniciais.csv 500 0.0001 sse_evolution_${num_t}_${sched}_${chunk}.csv)\n",
        "      echo \"$saida\" | grep \"Iteration\"\n",
        "\n",
        "      tempo=$(echo \"$saida\" | grep \"Tempo:\" | tail -n1 | sed -E 's/.*Tempo: ([0-9.]+) ms.*/\\1/')\n",
        "      sse_final=$(echo \"$saida\" | grep \"SSE final\" | sed -E 's/.*SSE final: ([0-9.eE+-]+) \\|.*/\\1/')\n",
        "      iters=$(echo \"$saida\" | grep \"Iterações\" | sed -E 's/.*Iterações: ([0-9]+).*/\\1/')\n",
        "      if [[ -z \"$tempo\" ]]; then tempo=9999999; fi\n",
        "\n",
        "      speedup=$(awk -v t_seq=\"$T_seq\" -v t_par=\"$tempo\" 'BEGIN{printf \"%.4f\", t_seq/t_par}')\n",
        "      eficiencia=$(awk -v s=\"$speedup\" -v n=\"$num_t\" 'BEGIN{printf \"%.4f\", s/n}')\n",
        "\n",
        "      echo \"→ [$sched,$chunk] Iterações: $iters | Tempo: ${tempo}ms | SSE final: $sse_final | SpeedUp: $speedup | Eficiência: $eficiencia\"\n",
        "      echo \"$num_t,$sched,$chunk,$tempo,$sse_final,$iters,$speedup,$eficiencia\" >> resultados.csv\n",
        "\n",
        "    else\n",
        "      for chunk in 1 10 100 1000; do\n",
        "        export OMP_SCHEDULE=\"$sched,$chunk\"\n",
        "        echo \"==========================================\"\n",
        "        echo \"Executando (Reduction): $sched (chunk=$chunk, threads=$num_t)\"\n",
        "        echo \"==========================================\"\n",
        "\n",
        "        saida=$(./kmeans_parallel_reduction dados.csv centroides_iniciais.csv 500 0.0001 sse_evolution_${num_t}_${sched}_${chunk}.csv)\n",
        "        echo \"$saida\" | grep \"Iteration\"\n",
        "\n",
        "        tempo=$(echo \"$saida\" | grep \"Tempo:\" | tail -n1 | sed -E 's/.*Tempo: ([0-9.]+) ms.*/\\1/')\n",
        "        sse_final=$(echo \"$saida\" | grep \"SSE final\" | sed -E 's/.*SSE final: ([0-9.eE+-]+) \\|.*/\\1/')\n",
        "        iters=$(echo \"$saida\" | grep \"Iterações\" | sed -E 's/.*Iterações: ([0-9]+).*/\\1/')\n",
        "        if [[ -z \"$tempo\" ]]; then tempo=9999999; fi\n",
        "\n",
        "        speedup=$(awk -v t_seq=\"$T_seq\" -v t_par=\"$tempo\" 'BEGIN{printf \"%.4f\", t_seq/t_par}')\n",
        "        eficiencia=$(awk -v s=\"$speedup\" -v n=\"$num_t\" 'BEGIN{printf \"%.4f\", s/n}')\n",
        "\n",
        "        echo \"→ [$sched,$chunk] Iterações: $iters | Tempo: ${tempo}ms | SSE final: $sse_final | SpeedUp: $speedup | Eficiência: $eficiencia\"\n",
        "        echo \"$num_t,$sched,$chunk,$tempo,$sse_final,$iters,$speedup,$eficiencia\" >> resultados.csv\n",
        "      done\n",
        "    fi\n",
        "  done\n",
        "done\n",
        "\n",
        "echo -e \"\\n=========== RESULTADOS FINAIS (REDUCTION) ===========\"\n",
        "column -t -s, resultados.csv\n"
      ],
      "metadata": {
        "id": "eIXrtmvkwZQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  D: Implementação Paralela (Opção B: Critical)\n",
        "\n",
        "Esta é a implementação paralela alternativa (`kmeans_1d_naive_parallel_critical.c`).\n",
        "\n",
        "- **`assignment_step_1d`**: Permanece igual, paralelizado com `reduction(+:sse)`.\n",
        "- **`update_step_1d`**: O laço de acumulação é paralelizado, mas em vez de `reduction`, ele usa `#pragma omp critical` para proteger as escritas nos vetores `sum` e `cnt`.\n",
        "\n",
        "O objetivo é comparar o desempenho desta abordagem, que serializa as atualizações (criando um gargalo), com a abordagem mais eficiente de `reduction`."
      ],
      "metadata": {
        "id": "impl_b_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile kmeans_1d_naive_parallel_critical.c\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "#include <math.h>\n",
        "#include <time.h>\n",
        "#include <omp.h>\n",
        "\n",
        "/* ---------- util CSV 1D: (funções inalteradas) ---------- */\n",
        "static int count_rows(const char *path){ /* ... (código inalterado) ... */ }\n",
        "static double *read_csv_1col(const char *path, int *n_out){ /* ... (código inalterado) ... */ }\n",
        "static void write_assign_csv(const char *path, const int *assign, int N){ /* ... (código inalterado) ... */ }\n",
        "static void write_centroids_csv(const char *path, const double *C, int K){ /* ... (código inalterado) ... */ }\n",
        "\n",
        "/* ---------- k-means 1D: Paralelizado com OpenMP ---------- */\n",
        "static double assignment_step_1d(const double *X, const double *C, int *assign, int N, int K){\n",
        "    double sse = 0.0;\n",
        "    #pragma omp parallel for schedule(runtime) reduction(+:sse)\n",
        "    for(int i=0;i<N;i++){\n",
        "        int best = -1;\n",
        "        double bestd = 1e300;\n",
        "        for(int c=0;c<K;c++){\n",
        "            double diff = X[i] - C[c];\n",
        "            double d = diff*diff;\n",
        "            if(d < bestd){ bestd = d; best = c; }\n",
        "        }\n",
        "        assign[i] = best;\n",
        "        sse += bestd;\n",
        "    }\n",
        "    return sse;\n",
        "}\n",
        "\n",
        "/* update: Versão alternativa usando omp critical */\n",
        "static void update_step_1d(const double *X, double *C, const int *assign, int N, int K){\n",
        "    double *sum = (double*)calloc((size_t)K, sizeof(double));\n",
        "    int *cnt = (int*)calloc((size_t)K, sizeof(int));\n",
        "    if(!sum || !cnt){ fprintf(stderr,\"Sem memoria no update\\n\"); exit(1); }\n",
        "\n",
        "    #pragma omp parallel for schedule(runtime)\n",
        "    for(int i = 0; i < N; i++){\n",
        "        int a = assign[i];\n",
        "        // Seção crítica serializa o acesso, criando um gargalo\n",
        "        #pragma omp critical\n",
        "        {\n",
        "            sum[a] += X[i];\n",
        "            cnt[a] += 1;\n",
        "        }\n",
        "    }\n",
        "    for(int c=0;c<K;c++){\n",
        "        if(cnt[c] > 0) C[c] = sum[c] / (double)cnt[c];\n",
        "        else           C[c] = X[0];\n",
        "    }\n",
        "    free(sum); free(cnt);\n",
        "}\n",
        "\n",
        "/* ---------- K-means principal (código inalterado) ---------- */\n",
        "static void kmeans_1d(const double *X, double *C, int *assign,\n",
        "                      int N, int K, int max_iter, double eps,\n",
        "                      int *iters_out, double *sse_out, FILE *f_sse)\n",
        "{\n",
        "    double prev_sse = 1e300;\n",
        "    double sse = 0.0;\n",
        "    int it;\n",
        "    for(it=0; it<max_iter; it++){\n",
        "        sse = assignment_step_1d(X, C, assign, N, K);\n",
        "        if(f_sse) fprintf(f_sse, \"%d,%.6f\\n\", it + 1, sse);\n",
        "        double rel = fabs(sse - prev_sse) / (prev_sse > 0.0 ? prev_sse : 1.0);\n",
        "        printf(\"Iteration %d, SSE: %f\\n\", it + 1, sse);\n",
        "        if(rel < eps){ it++; break; }\n",
        "        update_step_1d(X, C, assign, N, K);\n",
        "        prev_sse = sse;\n",
        "    }\n",
        "    *iters_out = it;\n",
        "    *sse_out = sse;\n",
        "}\n",
        "\n",
        "/* ---------- main (código inalterado, exceto printf) ---------- */\n",
        "int main(int argc, char **argv){\n",
        "    if(argc < 3){\n",
        "        printf(\"Uso: %s dados.csv centroides_iniciais.csv [max_iter=50] [eps=1e-4] [sse_iter.csv]\\n\", argv[0]);\n",
        "        return 1;\n",
        "    }\n",
        "    const char *pathX = argv[1];\n",
        "    const char *pathC = argv[2];\n",
        "    int max_iter = (argc>3)? atoi(argv[3]) : 50;\n",
        "    double eps   = (argc>4)? atof(argv[4]) : 1e-4;\n",
        "    const char *sse_file    = (argc>5)? argv[5] : NULL;\n",
        "    FILE *f_sse = NULL;\n",
        "    if(sse_file){\n",
        "        f_sse = fopen(sse_file, \"w\");\n",
        "        if(!f_sse){ fprintf(stderr,\"Erro ao abrir %s para escrita\\n\", sse_file); }\n",
        "        else fprintf(f_sse, \"iteracao,sse\\n\");\n",
        "    }\n",
        "    int N=0, K=0;\n",
        "    double *X = read_csv_1col(pathX, &N);\n",
        "    double *C = read_csv_1col(pathC, &K);\n",
        "    int *assign = (int*)malloc((size_t)N * sizeof(int));\n",
        "    if(!assign){ fprintf(stderr,\"Sem memoria para assign\\n\"); free(X); free(C); return 1; }\n",
        "    double t0 = omp_get_wtime();\n",
        "    int iters = 0; double sse = 0.0;\n",
        "    kmeans_1d(X, C, assign, N, K, max_iter, eps, &iters, &sse, f_sse);\n",
        "    double t1 = omp_get_wtime();\n",
        "    double ms = (t1 - t0) * 1000.0;\n",
        "    if(f_sse) fclose(f_sse);\n",
        "    printf(\"K-means 1D (Parallel - Critical)\\n\");\n",
        "    printf(\"N=%d K=%d max_iter=%d eps=%g\\n\", N, K, max_iter, eps);\n",
        "    printf(\"Threads: %d\\n\", omp_get_max_threads());\n",
        "    printf(\"Iterações: %d | SSE final: %.6f | Tempo: %.1f ms\\n\", iters, sse, ms);\n",
        "    free(assign); free(X); free(C);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "gNQzzRfowcid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# E: Benchmark (Opção B: Critical)\n",
        "\n",
        "Este script de shell executa o benchmark para a implementação com `#pragma omp critical`.\n",
        "\n",
        "O processo é idêntico ao da Etapa C, mas os resultados são salvos em `resultados_critical.csv` para comparação direta."
      ],
      "metadata": {
        "id": "bench_b_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "echo \"Compilando a versão paralela (Critical)...\"\n",
        "gcc -O2 -std=c99 -fopenmp kmeans_1d_naive_parallel_critical.c -o kmeans_parallel_critical -lm\n",
        "\n",
        "# Arquivo de resultados\n",
        "echo \"Num_Threads,Schedule,Chunk,Tempo(ms),SSE_final,Iteracoes,Speedup,Eficiência\" > resultados_critical.csv\n",
        "\n",
        "# Executa versão sequencial (T=1) para referência\n",
        "echo \"Executando o Baseline (Threads=1)...\"\n",
        "export OMP_NUM_THREADS=1\n",
        "export OMP_SCHEDULE=\"static\"\n",
        "T_seq=$(./kmeans_parallel_critical dados.csv centroides_iniciais.csv 500 0.0001 sse_evolution_seq_critical.csv | grep \"Tempo:\" | tail -n1 | sed -E 's/.*Tempo: ([0-9.]+) ms.*/\\1/')\n",
        "echo \"Tempo sequencial = $T_seq ms\"\n",
        "echo \"1,static,N/A,$T_seq,N/A,N/A,1.0000,1.0000\" >> resultados_critical.csv\n",
        "\n",
        "# Loop pelos schedules e threads\n",
        "for num_t in 2 4 8 16; do\n",
        "  export OMP_NUM_THREADS=$num_t\n",
        "\n",
        "  for sched in static dynamic; do\n",
        "    if [[ \"$sched\" == \"static\" ]]; then\n",
        "      export OMP_SCHEDULE=\"static\"\n",
        "      chunk=\"padrão\"\n",
        "\n",
        "      echo \"==========================================\"\n",
        "      echo \"Executando (Critical): $sched (chunk=$chunk, threads=$num_t)\"\n",
        "      echo \"==========================================\"\n",
        "\n",
        "      saida=$(./kmeans_parallel_critical dados.csv centroides_iniciais.csv 500 0.0001 sse_evolution_${num_t}_${sched}_${chunk}_critical.csv)\n",
        "      echo \"$saida\" | grep \"Iteration\"\n",
        "\n",
        "      tempo=$(echo \"$saida\" | grep \"Tempo:\" | tail -n1 | sed -E 's/.*Tempo: ([0-9.]+) ms.*/\\1/')\n",
        "      sse_final=$(echo \"$saida\" | grep \"SSE final\" | sed -E 's/.*SSE final: ([0-9.eE+-]+) \\|.*/\\1/')\n",
        "      iters=$(echo \"$saida\" | grep \"Iterações\" | sed -E 's/.*Iterações: ([0-9]+).*/\\1/')\n",
        "      if [[ -z \"$tempo\" ]]; then tempo=9999999; fi\n",
        "\n",
        "      speedup=$(awk -v t_seq=\"$T_seq\" -v t_par=\"$tempo\" 'BEGIN{printf \"%.4f\", t_seq/t_par}')\n",
        "      eficiencia=$(awk -v s=\"$speedup\" -v n=\"$num_t\" 'BEGIN{printf \"%.4f\", s/n}')\n",
        "\n",
        "      echo \"→ [$sched,$chunk] Iterações: $iters | Tempo: ${tempo}ms | SSE final: $sse_final | SpeedUp: $speedup | Eficiência: $eficiencia\"\n",
        "      echo \"$num_t,$sched,$chunk,$tempo,$sse_final,$iters,$speedup,$eficiencia\" >> resultados_critical.csv\n",
        "\n",
        "    else\n",
        "      for chunk in 1 10 100 1000; do\n",
        "        export OMP_SCHEDULE=\"$sched,$chunk\"\n",
        "        echo \"==========================================\"\n",
        "        echo \"Executando (Critical): $sched (chunk=$chunk, threads=$num_t)\"\n",
        "        echo \"==========================================\"\n",
        "\n",
        "        saida=$(./kmeans_parallel_critical dados.csv centroides_iniciais.csv 500 0.0001 sse_evolution_${num_t}_${sched}_${chunk}_critical.csv)\n",
        "        echo \"$saida\" | grep \"Iteration\"\n",
        "\n",
        "        tempo=$(echo \"$saida\" | grep \"Tempo:\" | tail -n1 | sed -E 's/.*Tempo: ([0-9.]+) ms.*/\\1/')\n",
        "        sse_final=$(echo \"$saida\" | grep \"SSE final\" | sed -E 's/.*SSE final: ([0-9.eE+-]+) \\|.*/\\1/')\n",
        "        iters=$(echo \"$saida\" | grep \"Iterações\" | sed -E 's/.*Iterações: ([0-9]+).*/\\1/')\n",
        "        if [[ -z \"$tempo\" ]]; then tempo=9999999; fi\n",
        "\n",
        "        speedup=$(awk -v t_seq=\"$T_seq\" -v t_par=\"$tempo\" 'BEGIN{printf \"%.4f\", t_seq/t_par}')\n",
        "        eficiencia=$(awk -v s=\"$speedup\" -v n=\"$num_t\" 'BEGIN{printf \"%.4f\", s/n}')\n",
        "\n",
        "        echo \"→ [$sched,$chunk] Iterações: $iters | Tempo: ${tempo}ms | SSE final: $sse_final | SpeedUp: $eficiencia\"\n",
        "        echo \"$num_t,$sched,$chunk,$tempo,$sse_final,$iters,$speedup,$eficiencia\" >> resultados_critical.csv\n",
        "      done\n",
        "    fi\n",
        "  done\n",
        "done\n",
        "\n",
        "echo -e \"\\n=========== RESULTADOS FINAIS (CRITICAL) ===========\"\n",
        "column -t -s, resultados_critical.csv\n"
      ],
      "metadata": {
        "id": "CkJ8ALwn1679"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  F: Análise de Convergência (Validação)\n",
        "\n",
        "Finalmente, plotamos os arquivos `sse_evolution_*.csv` gerados por todas as execuções. O objetivo é validar a corretude: todos os gráficos de convergência do SSE devem ser idênticos, provando que, apesar das diferentes técnicas de paralelização e tempos de execução, o resultado numérico final foi o mesmo."
      ],
      "metadata": {
        "id": "analysis_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Itera sobre todos os arquivos de log de SSE gerados\n",
        "for file in os.listdir('/content'):\n",
        "    if file.startswith('sse_evolution_') and file.endswith('.csv'):\n",
        "        path = os.path.join('/content', file)\n",
        "        try:\n",
        "            # Tenta ler o CSV, lidando com ou sem cabeçalho\n",
        "            try:\n",
        "                sse_df = pd.read_csv(path)\n",
        "                if not {'iteracao', 'sse'}.issubset(sse_df.columns):\n",
        "                    sse_df.columns = ['iteracao', 'sse']\n",
        "            except Exception:\n",
        "                sse_df = pd.read_csv(path, header=None, names=['iteracao', 'sse'])\n",
        "\n",
        "            # Limpa dados não numéricos que podem ter sido mal interpretados\n",
        "            sse_df = sse_df[pd.to_numeric(sse_df['iteracao'], errors='coerce').notna()]\n",
        "            sse_df = sse_df[pd.to_numeric(sse_df['sse'], errors='coerce').notna()]\n",
        "\n",
        "            # Converte os tipos para garantir a plotagem correta\n",
        "            sse_df['iteracao'] = sse_df['iteracao'].astype(int)\n",
        "            sse_df['sse'] = sse_df['sse'].astype(float)\n",
        "\n",
        "            if not sse_df.empty:\n",
        "                plt.figure(figsize=(8, 5))\n",
        "                plt.plot(sse_df['iteracao'], sse_df['sse'], linewidth=1.5)\n",
        "                plt.xlabel('Iteração')\n",
        "                plt.ylabel('SSE (Sum of Squared Errors)')\n",
        "                plt.title(f'Convergência ({file.replace(\"sse_evolution_\", \"\").replace(\".csv\",\"\")})')\n",
        "                plt.grid(True)\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar o arquivo {file}: {e}\")\n"
      ],
      "metadata": {
        "id": "unyYKmEV5SPQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}